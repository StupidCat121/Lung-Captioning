{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb3164a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.18\n",
      "Torch: 2.8.0+cu129\n",
      "Built with CUDA: 12.9\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch, platform\n",
    "\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Built with CUDA:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250b279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namth\\anaconda3\\envs\\lung_lora\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1009 21:45:32.551000 20348 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.9.11: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4050 Laptop GPU. Num GPUs = 1. Max memory: 5.997 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu129. CUDA: 8.9. CUDA Toolkit: 12.9. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastVisionModel\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-VL-3B-Instruct-bnb-4bit\",\n",
    "    load_in_4bit = True,\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52830999",
   "metadata": {},
   "source": [
    "‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ VLM ‡πÅ‡∏ö‡∏ö ‡∏™‡∏≠‡∏á‡∏á‡∏≤‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô: (1) ‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡πÇ‡∏£‡∏Ñ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û X-ray (classification) + (2) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏û (captioning) ‡∏ö‡∏ô‡∏ä‡∏∏‡∏î 6,000 ‡∏Ñ‡∏π‡πà‡∏†‡∏≤‡∏û‚Äì‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "\n",
    "‡∏≠‡∏≤‡∏Å‡∏≤‡∏£ ‚Äú‡∏ó‡∏≤‡∏¢‡πÇ‡∏£‡∏Ñ‡πÄ‡∏î‡∏¥‡∏°‡∏ã‡πâ‡∏≥ (‡πÄ‡∏ä‡πà‡∏ô normal) ‡∏à‡∏ô‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ï‡∏Å‡πÄ‡∏´‡∏•‡∏∑‡∏≠ ~0.17‚Äù ‡∏°‡∏±‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å catastrophic forgetting / class collapse ‡πÅ‡∏•‡∏∞ ‡∏≠‡∏¥‡∏°‡∏ö‡∏≤‡∏•‡∏≤‡∏ô‡∏ã‡πå‡∏Ç‡∏≠‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (‡∏™‡πà‡∏ß‡∏ô‡∏†‡∏≤‡∏©‡∏≤/‡πÅ‡∏Ñ‡∏õ‡∏ä‡∏±‡∏ô‡∏Å‡∏•‡∏ö‡∏á‡∏≤‡∏ô‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î)\n",
    "\n",
    "‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏£‡∏±‡∏á‡∏™‡∏µ = ‡πÉ‡∏´‡πâ ‚Äú‡∏™‡∏≤‡∏¢‡∏†‡∏≤‡∏û‚Äù ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏î‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤ ‚Äú‡∏™‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‚Äù ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏õ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏ß‡∏¢‡πÜ ‡πÅ‡∏ï‡πà ‡πÑ‡∏°‡πà‡∏à‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏™‡∏†‡∏≤‡∏û\n",
    "\n",
    "‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏´‡πâ ‚Äú‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏ö‡∏ö‡∏≠‡∏ô‡∏∏‡∏£‡∏±‡∏Å‡∏©‡πå‡∏ô‡∏¥‡∏¢‡∏°‚Äù: ‡∏ù‡∏∂‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ vision + cross-attention ‡∏Å‡πà‡∏≠‡∏ô, ‡∏Ñ‡∏∏‡∏° LoRA ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡∏≤‡∏á, ‡πÉ‡∏™‡πà dropout ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfit, ‡πÄ‡∏õ‡∏¥‡∏î rsLoRA ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Ç‡∏∂‡πâ‡∏ô ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å (6k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9df6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.15.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 1) PEFT / LoRA config (‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡πÇ‡∏à‡∏ó‡∏¢‡πå 2 ‡∏á‡∏≤‡∏ô: cls + cap)\n",
    "#    - ‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏±‡πâ‡∏á vision + attention ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏†‡∏≤‡∏û-‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "#    - ‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å \"‡∏Å‡∏±‡∏ô drift ‡∏†‡∏≤‡∏©‡∏≤\" ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î language MLP; ‡∏à‡∏∞‡∏Ñ‡πà‡∏≠‡∏¢ ‡πÜ ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ô‡∏£‡∏≠‡∏ö‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡πÑ‡∏î‡πâ\n",
    "#    - ‡πÉ‡∏ä‡πâ rsLoRA ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Å‡∏±‡∏ö rank ‡∏™‡∏π‡∏á\n",
    "# ==========================\n",
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = True,    # ‚úÖ ‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏™‡∏†‡∏≤‡∏û/feature ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á\n",
    "    finetune_language_layers   = False,   # ‚úÖ ‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å‡∏Å‡∏±‡∏ô drift ‡∏†‡∏≤‡∏©‡∏≤ (‡∏¢‡∏±‡∏á generate ‡πÑ‡∏î‡πâ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ head/weights ‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô infer)\n",
    "    finetune_attention_modules = True,    # ‚úÖ ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö cross-modal alignment (‡∏†‡∏≤‡∏û‚Üî‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)\n",
    "    finetune_mlp_modules       = False,   # ‚úÖ ‡∏•‡∏î‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏° ‡∏Å‡∏±‡∏ô overfit / catastrophic forgetting\n",
    "\n",
    "    r = 16,                # ‚úÖ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà 16; ‡∏ñ‡πâ‡∏≤ underfit ‡∏Ñ‡πà‡∏≠‡∏¢‡∏Ç‡∏¢‡∏±‡∏ö 32 ‡∏û‡∏£‡πâ‡∏≠‡∏° rsLoRA\n",
    "    lora_alpha = 16,       # ‚úÖ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö r ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ Unsloth\n",
    "    lora_dropout = 0.15,   # ‚úÖ ‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏±‡∏ô overfit/‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏î‡∏¥‡∏° (‡πÄ‡∏ä‡πà‡∏ô‡∏ï‡∏≠‡∏ö \"Normal\" ‡∏£‡∏±‡∏ß ‡πÜ)\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "\n",
    "    use_rslora = True,     # ‚úÖ ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Å‡∏±‡∏ö rank ‡∏™‡∏π‡∏á/‡∏á‡∏≤‡∏ô‡∏¢‡∏≤‡∏Å\n",
    "    loftq_config = None,   # ‚úÖ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏ó‡∏£‡∏ô 4-bit ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏õ‡∏¥‡∏î LoftQ ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û\n",
    "    # target_modules = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],  # ‚Üî ‡∏ñ‡πâ‡∏≤‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞ attention ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏Ñ‡πà‡∏≠‡∏¢‡∏õ‡∏•‡∏î‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af421c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "hf = load_from_disk(\"lung8_image_text_balanced\")\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á train/test (30%) ‡∏Å‡πà‡∏≠‡∏ô\n",
    "splits = hf.train_test_split(test_size=0.3, seed=42, shuffle=True)\n",
    "train_hf = splits[\"train\"]\n",
    "tmp_hf   = splits[\"test\"]\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á tmp ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô val/test ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡∏Ñ‡∏£‡∏∂‡πà‡∏á ‚Üí ‡πÑ‡∏î‡πâ 15/15\n",
    "vt = tmp_hf.train_test_split(test_size=0.99, seed=42, shuffle=True)\n",
    "val_hf  = vt[\"train\"]\n",
    "test_hf = vt[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3751e5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text', '__class__'],\n",
       "    num_rows: 5600\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30be106a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text', '__class__'],\n",
       "    num_rows: 24\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "936a07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Describe the chest X-ray using precise clinical terms. Identify one main diagnostic category from: Chest_Changes, Degenerative_Infectious, Higher_Density, Inflammatory_Pneumonia, Lower_Density, Mediastinal_Changes, Normal, or Obstructive.\"\n",
    "\n",
    "def convert_to_conversation(sample):\n",
    "    cls_name = sample[\"__class__\"]\n",
    "    description = sample[\"text\"]\n",
    "\n",
    "    answer = f\"Class: {cls_name}\\nExplanation: {description}\"\n",
    "    \n",
    "    conversation = [\n",
    "        {\"role\": \"user\", \"content\" : [\n",
    "            {\"type\" : \"text\",  \"text\"  : instruction},\n",
    "            {\"type\" : \"image\", \"image\" : sample[\"image\"]} ]\n",
    "        },\n",
    "        {\"role\" : \"assistant\", \"content\" : [\n",
    "            {\"type\" : \"text\", \"text\" : answer} ]\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    return {\"messages\" : conversation}\n",
    "\n",
    "train_ds = [convert_to_conversation(sample) for sample in train_hf]\n",
    "val_ds = [convert_to_conversation(sample) for sample in val_hf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ea7b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Describe the chest X-ray using precise clinical terms. Identify one main diagnostic category from: Chest_Changes, Degenerative_Infectious, Higher_Density, Inflammatory_Pneumonia, Lower_Density, Mediastinal_Changes, Normal, or Obstructive.'},\n",
       "    {'type': 'image',\n",
       "     'image': <PIL.JpegImagePlugin.JpegImageFile image mode=L size=450x450>}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Class: Mediastinal_Changes\\nExplanation: Pulmonary AVM (feeding/draining vessel on CT) seen as well-circumscribed nodular opacity with suspected vascular connections may reflect pulmonary AVM (confirm on CT/angio). Findings are compatible with Arteriovenous malformations (pulmonary AVM may project as nodular opacity). The nodular opacity with associated vascular structures is a key diagnostic feature. Further imaging, such as a dedicated CT angiogram, is crucial for confirmation.'}]}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b610a",
   "metadata": {},
   "source": [
    "‡∏Ñ‡πà‡∏≤ SFTTrainer ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡πâ‡∏≠‡∏á ‚Äú‡∏Å‡∏±‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡∏•‡πà‡∏°/‡∏ï‡∏≠‡∏ö‡∏ã‡πâ‡∏≥ normal‚Äù ‡πÅ‡∏•‡∏∞ ‚Äú‡∏Ñ‡∏∏‡∏°‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ captioning ‡∏Å‡∏•‡∏ö‡∏á‡∏≤‡∏ô‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‚Äù ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡∏ï‡∏ä‡πå‡πÄ‡∏≠‡∏ü‡πÄ‡∏ü‡∏Å‡∏ó‡∏µ‡∏ü‡πÉ‡∏´‡∏ç‡πà‡∏û‡∏≠, ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏û‡∏≠‡∏î‡∏µ, ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ñ‡∏µ‡πà, ‡πÄ‡∏ã‡∏ü‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡∏∞ (‡∏ñ‡πâ‡∏≤‡∏ó‡∏≥‡πÑ‡∏î‡πâ) ‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å loss ‡πÉ‡∏´‡πâ‡∏ù‡∏±‡πà‡∏á classification ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤\n",
    "\n",
    "‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö compute_metrics ‡πÑ‡∏°‡πà ‚Äú‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‚Äù ‡πÅ‡∏ï‡πà ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏≤‡∏™‡∏•‡πà‡∏°/‡πÄ‡∏î‡∏≤‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÄ‡∏ä‡πà‡∏ô normal ‡∏£‡∏±‡∏ß ‡πÜ) ‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏™‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (accuracy/F1 ‡∏ï‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™, BLEU/CIDEr ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Ñ‡∏õ‡∏ä‡∏±‡∏ô) ‡πÅ‡∏ó‡∏ô‡∏à‡∏∞‡∏î‡∏π loss ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2942a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import is_bf16_supported, FastVisionModel\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from transformers import EarlyStoppingCallback, TrainerCallback\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch, math, random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eae1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 2) ‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏á‡∏≤‡∏ô (label set) ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏•‡πá‡∏Å ‡πÜ\n",
    "# ==========================\n",
    "CLASS_LABELS = [\n",
    "    \"Chest_Changes\", \"Degenerative_Infectious\", \"Higher_Density\",\n",
    "    \"Inflammatory_Pneumonia\", \"Lower_Density\", \"Mediastinal_Changes\",\n",
    "    \"Normal\", \"Obstructive\",\n",
    "]\n",
    "LABEL_SET = set(CLASS_LABELS)\n",
    "LABEL_TO_ID = {c:i for i,c in enumerate(CLASS_LABELS)}\n",
    "\n",
    "def extract_pred_class(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ‡∏î‡∏∂‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•:\n",
    "    ‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á/‡πÄ‡∏Ñ‡∏™/‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏•‡∏±‡∏ö/‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
    "    \"\"\"\n",
    "    # ‡∏´‡∏≤ \"Class: <‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™>\"\n",
    "    m = re.search(r\"(?i)class\\s*:\\s*([A-Za-z0-9_\\- ]+)\", text)\n",
    "    if not m:\n",
    "        return None\n",
    "    raw = m.group(1).strip()\n",
    "    # ‡∏ó‡∏≥ normalization ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
    "    cand = raw.replace(\" \", \"_\")\n",
    "    # ‡πÄ‡∏ä‡πá‡∏Ñ map ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å (‡πÅ‡∏ö‡∏ö‡∏´‡∏¢‡∏ß‡∏ô‡πÜ)\n",
    "    # ‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏ï‡∏±‡∏ß‡∏Å‡πà‡∏≠‡∏ô\n",
    "    if cand in LABEL_TO_ID: \n",
    "        return cand\n",
    "    # ‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ö‡∏ö lower-case\n",
    "    for c in CLASS_LABELS:\n",
    "        if cand.lower() == c.lower():\n",
    "            return c\n",
    "    # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô None ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏à‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d59ebddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = \"\"\"\n",
    "Class: mEdiAsTinal cHanges\n",
    "Explanation: The chest X-ray shows increased transparency adjacent to both right and left cardiophrenic angles with variable clarity indicating partial atelectasis or pneumonia. This imaging feature suggests inflammatory change that is consistent with an underlying infectious etiology in this setting. The clinical scenario strongly supports infection leading to lung parenchymal changes. There are no visible effusions, mass lesions, or linear changes typical for entities like neoplasms or autoimmune conditions. The features are compatible with Degenerative_Infectious based on clinical and radiographic correlation, particularly considering the known clinical presentations associated with specific conditions in similar\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b1528e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mediastinal_Changes'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_pred_class(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fda2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_l_f1(pred: str, ref: str) -> float:\n",
    "    \"\"\"\n",
    "    ROUGE-L F1 ‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ (‡πÑ‡∏°‡πà‡∏û‡∏∂‡πà‡∏á external lib) ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [0,1]\n",
    "    ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô proxy ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û captioning ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ CIDEr\n",
    "    \"\"\"\n",
    "    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô token ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ö‡∏ö‡∏´‡∏¢‡∏≤‡∏ö ‡πÜ\n",
    "    def tok(s): \n",
    "        return [w for w in s.strip().split() if w]\n",
    "    x, y = tok(pred.lower()), tok(ref.lower())\n",
    "    if not x or not y:\n",
    "        return 0.0\n",
    "    # LCS length (dynamic programming)\n",
    "    m, n = len(x), len(y)\n",
    "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if x[i] == y[j]:\n",
    "                dp[i+1][j+1] = dp[i][j] + 1\n",
    "            else:\n",
    "                dp[i+1][j+1] = max(dp[i][j+1], dp[i+1][j])\n",
    "    lcs = dp[m][n]\n",
    "    prec = lcs / max(1, m)\n",
    "    rec  = lcs / max(1, n)\n",
    "    if prec + rec == 0:\n",
    "        return 0.0\n",
    "    return 2 * prec * rec / (prec + rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a53fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_t = \"\"\"\n",
    "Class: Mediastinal_Changes\n",
    "Explanation: Findings are compatible with Arteriovenous malformations (pulmonary AVM may project as nodular opacity), characterized by well-circumscribed nodular opacity with suspected vascular connections may reflect pulmonary AVM (confirm on CT/angio). The nodular opacity warrants careful evaluation. Further imaging, such as a CT angiogram, is crucial for confirmation and characterization of feeding/draining vessels.\n",
    "\"\"\"\n",
    "\n",
    "ref_f = \"\"\"\n",
    "Class: Degenerative_Infectious\n",
    "Explanation: Reticulonodular pattern / interstitial fibrosis with coarse reticular opacities with volume loss, basilar and peripheral predominance (fibrotic pattern on CXR). Findings are compatible with Pulmonary fibrosis (e.g., IPF pattern on CXR). The reticular opacities are most evident in the lower lobes and periphery. There is associated volume loss and architectural distortion. These findings are highly suggestive of a fibrotic lung disease.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fce834c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09333333333333334"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_l_f1(test_pred, ref_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48fda8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_l_f1(test_pred, ref_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81b6abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1_from_predictions(y_true: List[int], y_pred: List[int]) -> float:\n",
    "    \"\"\"\n",
    "    macro-F1 ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏∂‡πà‡∏á sklearn (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° self-contained)\n",
    "    \"\"\"\n",
    "    num_classes = len(CLASS_LABELS)\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á confusion ‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡∏ö TP/FP/FN ‡∏ï‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™\n",
    "    tp = [0]*num_classes\n",
    "    fp = [0]*num_classes\n",
    "    fn = [0]*num_classes\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yp == yt:\n",
    "            tp[yt] += 1\n",
    "        else:\n",
    "            fp[yp] += 1\n",
    "            fn[yt] += 1\n",
    "    f1s = []\n",
    "    for c in range(num_classes):\n",
    "        p = tp[c] / max(1, (tp[c] + fp[c]))\n",
    "        r = tp[c] / max(1, (tp[c] + fn[c]))\n",
    "        if p + r == 0:\n",
    "            f1s.append(0.0)\n",
    "        else:\n",
    "            f1s.append(2*p*r/(p+r))\n",
    "    return float(np.mean(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad602ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 3) Callback: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô cls + cap ‡πÅ‡∏•‡πâ‡∏ß \"‡∏•‡πá‡∏≠‡∏Å\" metric (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô KeyError)\n",
    "# ==========================\n",
    "class CaptionEvalCallback(TrainerCallback):\n",
    "    def __init__(self, eval_dataset, tokenizer, sample_size=256, max_new_tokens=96, seed=42):\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sample_size = sample_size\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "        self.rng = random.Random(seed)\n",
    "\n",
    "    # --- ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ messages ‡πÉ‡∏ô row ---\n",
    "    def build_messages(self, image_obj) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        ‡∏Å‡∏£‡∏ì‡∏µ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤ (‡∏°‡∏µ 'image' ‡πÅ‡∏•‡∏∞ 'text') ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ 'messages'\n",
    "        ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° user ‡∏ï‡∏≤‡∏° prompt ‡πÄ‡∏î‡∏¥‡∏° + ‡πÅ‡∏ô‡∏ö‡∏†‡∏≤‡∏û\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\",\n",
    "                         \"text\": (\n",
    "                            \"Describe the chest X-ray using precise clinical terms. \"\n",
    "                            \"Identify one main diagnostic category from: \"\n",
    "                            \"Chest_Changes, Degenerative_Infectious, Higher_Density, \"\n",
    "                            \"Inflammatory_Pneumonia, Lower_Density, Mediastinal_Changes, \"\n",
    "                            \"Normal, or Obstructive.\"\n",
    "                         )},\n",
    "                        {\"type\": \"image\", \"image\": image_obj},\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def _extract_from_row(self, row: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å‡∏Å‡∏£‡∏ì‡∏µ:\n",
    "        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ 'messages': ‡πÉ‡∏ä‡πâ messages ‡πÄ‡∏î‡∏¥‡∏° (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢, ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á chat template)\n",
    "            * ‡∏£‡∏π‡∏õ: ‡∏Ñ‡πâ‡∏ô‡πÉ‡∏ô user.content[type=='image']\n",
    "            * ref_caption: ‡πÉ‡∏ä‡πâ assistant.content[type=='text'] ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'text'\n",
    "        - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ 'messages': ‡πÉ‡∏ä‡πâ row['image'] + row['text'] ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏£‡πâ‡∏≤‡∏á messages ‡πÉ‡∏´‡∏°‡πà\n",
    "\n",
    "        ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: messages(dict), ref_caption(str), true_cls(str)\n",
    "        \"\"\"\n",
    "        messages = None\n",
    "        ref_caption = row.get(\"text\", \"\") or \"\"       # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ 'text' ‡∏à‡∏∞‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏à‡∏≤‡∏Å assistant ‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á\n",
    "        true_cls = row.get(\"__class__\", \"\") or \"\"     # label ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™\n",
    "\n",
    "        if \"messages\" in row and isinstance(row[\"messages\"], list):\n",
    "            # ‡πÉ‡∏ä‡πâ messages ‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á mismatch ‡∏Å‡∏±‡∏ö processor/data_collator\n",
    "            messages = {\"messages\": row[\"messages\"]}\n",
    "\n",
    "            # ‡∏´‡∏≤ image ‡∏à‡∏≤‡∏Å user turn ‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ type=='image'\n",
    "            image_found = False\n",
    "            for turn in row[\"messages\"]:\n",
    "                if turn.get(\"role\") == \"user\":\n",
    "                    for c in (turn.get(\"content\") or []):\n",
    "                        if isinstance(c, dict) and c.get(\"type\") == \"image\" and c.get(\"image\") is not None:\n",
    "                            image_found = True\n",
    "                            break\n",
    "                if image_found:\n",
    "                    break\n",
    "\n",
    "            # ‡∏´‡∏≤ ref caption ‡∏à‡∏≤‡∏Å assistant ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ 'text'\n",
    "            if not ref_caption:\n",
    "                for turn in row[\"messages\"]:\n",
    "                    if turn.get(\"role\") == \"assistant\":\n",
    "                        for c in (turn.get(\"content\") or []):\n",
    "                            if isinstance(c, dict) and c.get(\"type\") == \"text\" and c.get(\"text\"):\n",
    "                                ref_caption = c[\"text\"]\n",
    "                                break\n",
    "                        if ref_caption:\n",
    "                            break\n",
    "\n",
    "            # ‡∏ñ‡πâ‡∏≤ messages ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏û‡πÄ‡∏•‡∏¢ (rare) ‚Üí ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° fallback ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏µ‡∏¢‡πå 'image'\n",
    "            if not image_found and row.get(\"image\", None) is not None:\n",
    "                messages = self.build_messages(row[\"image\"])\n",
    "\n",
    "        else:\n",
    "            # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ 'image' ‡∏à‡∏∂‡∏á‡∏à‡∏∞ build ‡πÑ‡∏î‡πâ\n",
    "            img = row.get(\"image\", None)\n",
    "            if img is None:\n",
    "                # ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‚Üí ‡πÇ‡∏¢‡∏ô error ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏ó‡∏ô KeyError\n",
    "                raise ValueError(\n",
    "                    \"No image found in row. Expected either 'messages' with an image content \"\n",
    "                    \"or an 'image' column.\"\n",
    "                )\n",
    "            messages = self.build_messages(img)\n",
    "\n",
    "        return messages, ref_caption, true_cls\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def on_evaluate(self, args, state, control, model=None, **kwargs):\n",
    "        model.eval()\n",
    "\n",
    "        # ----- ‡∏™‡∏∏‡πà‡∏° subset ‡∏à‡∏≤‡∏Å val_ds ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤ evaluate -----\n",
    "        n = len(self.eval_dataset)\n",
    "        idxs = list(range(n))\n",
    "        self.rng.shuffle(idxs)\n",
    "        idxs = idxs[:min(self.sample_size, n)]\n",
    "\n",
    "        pred_classes, true_classes = [], []\n",
    "        rouge_ls = []\n",
    "\n",
    "        for i in idxs:\n",
    "            row = self.eval_dataset[i]\n",
    "\n",
    "            # ‚úÖ ‡∏î‡∏∂‡∏á messages/ref/label ‡πÅ‡∏ö‡∏ö‡∏Å‡∏±‡∏ô‡∏û‡∏±‡∏á ‡πÑ‡∏°‡πà‡∏ú‡∏π‡∏Å‡∏ï‡∏¥‡∏î‡∏Ñ‡∏µ‡∏¢‡πå 'image'\n",
    "            messages, ref_caption, true_cls = self._extract_from_row(row)\n",
    "\n",
    "            # ----- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏ï‡∏≤‡∏° template ‡∏Ç‡∏≠‡∏á‡∏£‡∏∏‡πà‡∏ô (‡πÉ‡∏ä‡πâ messages ‡∏ó‡∏µ‡πà‡∏™‡∏Å‡∏±‡∏î‡πÑ‡∏î‡πâ) -----\n",
    "            inputs = self.tokenizer.apply_chat_template(\n",
    "                messages[\"messages\"],\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "\n",
    "            # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: Unsloth FastVisionModel ‡∏à‡∏∞ map ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å messages ‡∏ú‡πà‡∏≤‡∏ô data_collator/processor ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô\n",
    "            # ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏£‡∏∏‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ kwargs ‡πÄ‡∏û‡∏¥‡πà‡∏° (‡πÄ‡∏ä‡πà‡∏ô pixel_values) ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏±‡∏ö data_collator ‡πÉ‡∏´‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô\n",
    "\n",
    "            # ----- Generate -----\n",
    "            out = model.generate(\n",
    "                input_ids=inputs,\n",
    "                max_new_tokens=self.max_new_tokens,\n",
    "                do_sample=False\n",
    "            )\n",
    "            text = self.tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "            # ----- ‡πÅ‡∏¢‡∏Å \"‡∏Ñ‡∏•‡∏≤‡∏™\" ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ROUGE-L caption -----\n",
    "            pred_cls_str = extract_pred_class(text) or \"\"   # string ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå\n",
    "            if pred_cls_str in LABEL_SET:\n",
    "                pred_classes.append(LABEL_TO_ID[pred_cls_str])\n",
    "            else:\n",
    "                pred_classes.append(-1)  # ‡∏ñ‡πâ‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å‡πÉ‡∏´‡πâ mark -1 ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á\n",
    "\n",
    "            true_classes.append(LABEL_TO_ID.get(true_cls, -1))\n",
    "\n",
    "            # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ ref_caption ‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà \"\" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ rouge_l_f1 ‡∏Ñ‡∏∑‡∏ô 0 ‡πÅ‡∏ó‡∏ô‡∏û‡∏±‡∏á\n",
    "            rouge_ls.append(rouge_l_f1(text, ref_caption or \"\"))\n",
    "\n",
    "        # ----- ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ -1 -----\n",
    "        y_true_clean, y_pred_clean = [], []\n",
    "        for yt, yp in zip(true_classes, pred_classes):\n",
    "            if yt >= 0 and yp >= 0:\n",
    "                y_true_clean.append(yt)\n",
    "                y_pred_clean.append(yp)\n",
    "\n",
    "        macro_f1 = macro_f1_from_predictions(y_true_clean, y_pred_clean) if y_true_clean else 0.0\n",
    "        rougeL   = float(np.mean(rouge_ls)) if rouge_ls else 0.0\n",
    "\n",
    "        # ----- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metric ‡πÅ‡∏ö‡∏ö IN-PLACE ‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏µ‡∏¢‡πå‡∏õ‡∏Å‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏µ‡∏¢‡πå eval_ -----\n",
    "        metrics = kwargs.get(\"metrics\", None)\n",
    "        if metrics is not None:\n",
    "            # ‡∏Ñ‡∏µ‡∏¢‡πå‡∏õ‡∏Å‡∏ï‡∏¥ (‡∏î‡∏π‡∏Å‡∏£‡∏≤‡∏ü/log ‡πÑ‡∏î‡πâ‡∏™‡∏∞‡∏î‡∏ß‡∏Å)\n",
    "            metrics[\"macro_f1\"] = macro_f1\n",
    "            metrics[\"rougeL\"]   = rougeL\n",
    "            # ‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà Trainer ‡∏à‡∏∞‡∏´‡∏≤‡πÅ‡∏ô‡πà ‡πÜ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏° prefix 'eval_'\n",
    "            metrics[\"eval_macro_f1\"] = macro_f1\n",
    "            metrics[\"eval_rougeL\"]   = rougeL\n",
    "        # ‡∏´‡πâ‡∏≤‡∏° reassign ‡πÄ‡∏õ‡πá‡∏ô kwargs[\"metrics\"] = {...}  ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ in-place ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "\n",
    "        return control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed752a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 4) Callback: Gate ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å captioning (‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥) + Early stopping ‡πÄ‡∏™‡∏£‡∏¥‡∏°\n",
    "#    - auto-resolve ‡∏Ñ‡∏µ‡∏¢‡πå metric ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡∏°‡∏µ/‡πÑ‡∏°‡πà‡∏°‡∏µ prefix 'eval_'\n",
    "#    - ‡∏Å‡∏±‡∏ô NaN / missing metric\n",
    "# ==========================\n",
    "class SecondaryMetricGate(TrainerCallback):\n",
    "    def __init__(self, metric_key=\"rougeL\", min_value=0.35, patience=2):\n",
    "        \"\"\"\n",
    "        metric_key: ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å gate (‡πÄ‡∏ä‡πà‡∏ô \"rougeL\" ‡∏´‡∏£‡∏∑‡∏≠ \"eval_rougeL\")\n",
    "        min_value : ‡∏Ñ‡πà‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö (‡∏¢‡∏¥‡πà‡∏á‡∏°‡∏≤‡∏Å‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ)\n",
    "        patience  : ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏Å‡∏µ‡πà‡∏£‡∏≠‡∏ö‡∏à‡∏∂‡∏á‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏ó‡∏£‡∏ô\n",
    "        \"\"\"\n",
    "        self.metric_key = str(metric_key)\n",
    "        self.min_value = float(min_value)\n",
    "        self.patience = int(patience)\n",
    "        self.bad_epochs = 0\n",
    "        self._resolved_key = None  # ‡∏à‡∏∞ cache ‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô 'rougeL' ‡∏´‡∏£‡∏∑‡∏≠ 'eval_rougeL'\n",
    "\n",
    "    def _resolve_key(self, metrics: dict):\n",
    "        \"\"\"\n",
    "        ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤ \"‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á\" ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏•‡πâ‡∏ß cache ‡πÑ‡∏ß‡πâ:\n",
    "            - ‡∏ï‡∏£‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á‡∏°‡∏≤ (metric_key)\n",
    "            - ‡πÄ‡∏ï‡∏¥‡∏°/‡∏ï‡∏±‡∏î prefix 'eval_'\n",
    "        \"\"\"\n",
    "        if self._resolved_key is not None:\n",
    "            return  # ‡πÄ‡∏Ñ‡∏¢ resolve ‡πÅ‡∏•‡πâ‡∏ß\n",
    "\n",
    "        candidates = [self.metric_key]\n",
    "        if self.metric_key.startswith(\"eval_\"):\n",
    "            candidates.append(self.metric_key[len(\"eval_\"):])           # ‡∏ï‡∏±‡∏î eval_\n",
    "        else:\n",
    "            candidates.append(f\"eval_{self.metric_key}\")                 # ‡πÄ‡∏ï‡∏¥‡∏° eval_\n",
    "\n",
    "        for k in candidates:\n",
    "            if k in metrics:\n",
    "                self._resolved_key = k\n",
    "                break\n",
    "        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏á None ‡πÅ‡∏•‡πâ‡∏ß‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏ú‡πà‡∏≤‡∏ô‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà gate)\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        metrics = kwargs.get(\"metrics\", {}) or {}\n",
    "\n",
    "        # ‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏µ‡∏¢‡πå‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å metrics ‡∏Ç‡∏≠‡∏á‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "        self._resolve_key(metrics)\n",
    "\n",
    "        if not self._resolved_key:\n",
    "            # ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ ‚Üí ‡πÑ‡∏°‡πà gate\n",
    "            return control\n",
    "\n",
    "        val = metrics.get(self._resolved_key, None)\n",
    "        # ‡∏Å‡∏±‡∏ô NaN / None\n",
    "        try:\n",
    "            import math\n",
    "            if val is None or not math.isfinite(float(val)):\n",
    "                return control  # ‡πÑ‡∏°‡πà gate ‡∏ñ‡πâ‡∏≤‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ\n",
    "        except Exception:\n",
    "            return control\n",
    "\n",
    "        if float(val) < self.min_value:\n",
    "            # 1) ‡πÑ‡∏°‡πà save checkpoint ‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ (‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡∏ó‡∏µ‡πà caption ‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å)\n",
    "            control.should_save = False\n",
    "            # 2) ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à early stop\n",
    "            self.bad_epochs += 1\n",
    "            if self.bad_epochs >= self.patience:\n",
    "                control.should_training_stop = True\n",
    "        else:\n",
    "            self.bad_epochs = 0  # reset ‡∏ñ‡πâ‡∏≤‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå\n",
    "\n",
    "        return control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "800c8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 5) ‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ö‡∏ô GPU (TF32) + ‡πÄ‡∏õ‡∏¥‡∏î train\n",
    "# ==========================\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "FastVisionModel.for_training(model)  # ‚úÖ enable training\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10109336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==========================\n",
    "# # 6) ‡∏™‡∏£‡πâ‡∏≤‡∏á Trainer + ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å \"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\" ‡∏î‡πâ‡∏ß‡∏¢ macro_f1\n",
    "# #    - eval/save ‡πÅ‡∏ö‡∏ö steps ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ callback ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ñ‡∏µ‡πà‡∏û‡∏≠\n",
    "# #    - remove_unused_columns=False ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö VLM (‡∏£‡∏±‡∏Å‡∏©‡∏≤ fields image/messages)\n",
    "# # ==========================\n",
    "# trainer = SFTTrainer(\n",
    "#     model = model,\n",
    "#     tokenizer = tokenizer,\n",
    "#     data_collator = UnslothVisionDataCollator(model, tokenizer),\n",
    "#     train_dataset = train_ds,\n",
    "#     eval_dataset = val_ds,\n",
    "#     args = SFTConfig(\n",
    "#         # ===== core =====\n",
    "#         output_dir=\"./outs\",\n",
    "#         per_device_train_batch_size=2,\n",
    "#         gradient_accumulation_steps=16,\n",
    "#         learning_rate=1e-4,\n",
    "#         num_train_epochs=2,\n",
    "#         warmup_ratio=0.05,\n",
    "#         weight_decay=0.01,\n",
    "#         lr_scheduler_type=\"linear\",\n",
    "\n",
    "#         # ===== precision =====\n",
    "#         bf16 = is_bf16_supported(),   # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏°‡∏Æ‡∏≤‡∏£‡πå‡∏î‡πÅ‡∏ß‡∏£‡πå (Ampere+)\n",
    "#         tf32 = True,\n",
    "\n",
    "#         # ===== eval/save =====\n",
    "#         eval_strategy=\"steps\",\n",
    "#         eval_steps=300,\n",
    "#         save_strategy=\"steps\",\n",
    "#         save_steps=300,\n",
    "#         load_best_model_at_end=True,\n",
    "\n",
    "#         # ‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ï‡∏≤‡∏° \"macro_f1\" (‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å: classification)\n",
    "#         metric_for_best_model=\"macro_f1\",\n",
    "#         greater_is_better=True,\n",
    "\n",
    "#         logging_steps=10,\n",
    "#         save_total_limit=3,           # ‚úÖ ‡∏Å‡∏±‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡πÄ‡∏¢‡∏≠‡∏∞\n",
    "\n",
    "#         # ===== VLM safety =====\n",
    "#         remove_unused_columns=False,  # ‚úÖ ‡∏≠‡∏¢‡πà‡∏≤‡∏ï‡∏±‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå messages/image\n",
    "#         dataloader_num_workers=0,     # ‚úÖ ‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤ pickle/vision worker\n",
    "#         dataset_num_proc=1,           # ‚úÖ ‡∏Å‡∏±‡∏ô map ‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏õ‡∏£‡πÄ‡∏ã‡∏™ (‡∏™‡πÄ‡∏ñ‡∏µ‡∏¢‡∏£)\n",
    "#         per_device_eval_batch_size=2, # ‚úÖ ‡∏•‡∏î VRAM ‡∏Ç‡∏ì‡∏∞ eval+generate\n",
    "#     ),\n",
    "#     # ‡πÄ‡∏£‡∏≤ \"‡πÑ‡∏°‡πà\" ‡πÉ‡∏ä‡πâ compute_metrics ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö SFTTrainer ‡∏ï‡∏£‡∏á ‡πÜ\n",
    "#     # ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ VLM+generate ‡∏°‡∏±‡∏Å‡∏ä‡∏ô‡∏Å‡∏±‡∏ö _pad_across_processes; ‡∏à‡∏∂‡∏á‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ callback\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84ac35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==========================\n",
    "# # 7) ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Callback:\n",
    "# #    - EarlyStopping: ‡∏≠‡∏¥‡∏á metric_for_best_model (macro_f1)\n",
    "# #    - CaptionEvalCallback: ‡πÄ‡∏ï‡∏¥‡∏° macro_f1 + rougeL ‡∏•‡∏á metrics ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà eval\n",
    "# #    - SecondaryMetricGate: ‡∏Å‡∏±‡πâ‡∏ô checkpoint/‡∏´‡∏¢‡∏∏‡∏î ‡∏´‡∏≤‡∏Å caption ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå\n",
    "# # ==========================\n",
    "# trainer.add_callback(EarlyStoppingCallback(\n",
    "#     early_stopping_patience=5,         # ‡∏ñ‡πâ‡∏≤ macro_f1 ‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô 5 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡∏¥‡∏î ‚Üí ‡∏´‡∏¢‡∏∏‡∏î\n",
    "#     early_stopping_threshold=1e-4\n",
    "# ))\n",
    "# trainer.add_callback(CaptionEvalCallback(\n",
    "#     eval_dataset=val_ds,\n",
    "#     tokenizer=tokenizer,\n",
    "#     sample_size=64,                   # ‚úÖ subset ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ)\n",
    "#     max_new_tokens=96\n",
    "# ))\n",
    "# trainer.add_callback(SecondaryMetricGate(\n",
    "#     metric_key=\"rougeL\",               # ‚úÖ ‡πÉ‡∏ä‡πâ ROUGE-L ‡πÄ‡∏õ‡πá‡∏ô proxy ‡∏Ç‡∏≠‡∏á caption ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û\n",
    "#     min_value=0.35,                    # ‚úÖ ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ (‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ê‡∏≤‡∏ô)\n",
    "#     patience=2\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6dfdd04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Model does not have a default image size - using 512\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = UnslothVisionDataCollator(model, tokenizer),\n",
    "    train_dataset = train_ds,\n",
    "    eval_dataset = val_ds,\n",
    "    args = SFTConfig(\n",
    "        output_dir=\"./outs_fast\",\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=1e-4,\n",
    "        num_train_epochs=1,\n",
    "        max_steps=42,\n",
    "        warmup_ratio=0.0,\n",
    "        weight_decay=0.0,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        bf16 = is_bf16_supported(),\n",
    "        tf32 = True,\n",
    "\n",
    "        # ---- eval/save ----\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=40,\n",
    "        save_strategy=\"no\",          # ‡πÑ‡∏°‡πà‡πÄ‡∏ã‡∏ü ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î I/O\n",
    "        load_best_model_at_end=False,# ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å best\n",
    "\n",
    "        # ‚õî ‡∏•‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏ó‡∏¥‡πâ‡∏á‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏ó‡∏™‡∏ï‡πå:\n",
    "        metric_for_best_model=\"macro_f1\",\n",
    "        greater_is_better=True,\n",
    "\n",
    "        logging_steps=5,\n",
    "        save_total_limit=1,\n",
    "\n",
    "        remove_unused_columns=False,\n",
    "        dataloader_num_workers=0,\n",
    "        dataset_num_proc=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee0e44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏£‡πá‡∏ß: ‡πÉ‡∏ä‡πâ subset ‡πÄ‡∏•‡πá‡∏Å + generate ‡∏™‡∏±‡πâ‡∏ô\n",
    "trainer.add_callback(CaptionEvalCallback(\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    sample_size=32,        # ‡∏à‡∏≤‡∏Å 256 ‚Üí 32 ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å\n",
    "    max_new_tokens=40      # ‡∏à‡∏≤‡∏Å 96 ‚Üí 40 ‡∏û‡∏≠‡∏à‡∏±‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÑ‡∏î‡πâ\n",
    "))\n",
    "# ‡πÄ‡∏Å‡∏ó‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û caption ‡πÉ‡∏´‡πâ‡πÄ‡∏ö‡∏≤‡∏•‡∏á‡∏´‡∏ô‡πà‡∏≠‡∏¢ (‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ß‡∏•‡∏≤)\n",
    "trainer.add_callback(SecondaryMetricGate(\n",
    "    metric_key=\"rougeL\",\n",
    "    min_value=0.30,        # ‡∏ú‡πà‡∏≠‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏ó‡∏™‡∏ï‡πå\n",
    "    patience=1             # ‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≥ 1 ‡∏£‡∏≠‡∏ö‡∏ï‡∏¥‡∏î‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4badd9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4050 Laptop GPU. Max memory = 5.997 GB.\n",
      "3.445 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c612f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 5,600 | Num Epochs = 1 | Total steps = 42\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 3,932,160 of 3,758,555,136 (0.10% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 05:30, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.952200</td>\n",
       "      <td>3.649269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import unsloth_train\n",
    "\n",
    "trainer_stats = unsloth_train(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f06a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334.044 seconds used for training.\n",
      "5.57 minutes used for training.\n",
      "Peak reserved memory = 11.316 GB.\n",
      "Peak reserved memory for training = 7.871 GB.\n",
      "Peak reserved memory % of max memory = 188.694 %.\n",
      "Peak reserved memory for training % of max memory = 131.249 %.\n"
     ]
    }
   ],
   "source": [
    "# title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "932b58e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final metrics: {'train_runtime': 334.044, 'train_samples_per_second': 0.503, 'train_steps_per_second': 0.126, 'total_flos': 1458142636277760.0, 'train_loss': 0.9359203236443656, 'epoch': 0.03}\n",
      "Latest eval_loss: 3.6492691040039062 (step=40, epoch=0.02857142857142857)\n"
     ]
    }
   ],
   "source": [
    "# ‡∏û‡∏¥‡∏°‡∏û‡πå metric ‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏¥‡∏°\n",
    "print(\"Final metrics:\", trainer_stats.metrics)\n",
    "\n",
    "# ‡∏î‡∏∂‡∏á eval_loss ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡πâ‡∏≠‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å log_history\n",
    "def latest_eval_metric(trainer, key=\"eval_loss\"):\n",
    "    # log_history ‡πÄ‡∏Å‡πá‡∏ö dict ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö: {'eval_loss': ..., 'step': ..., 'epoch': ...}\n",
    "    for log in reversed(trainer.state.log_history):\n",
    "        if key in log:\n",
    "            return {\n",
    "                \"value\": log[key],\n",
    "                \"step\": log.get(\"step\", log.get(\"global_step\", None)),\n",
    "                \"epoch\": log.get(\"epoch\", None),\n",
    "                \"raw\": log,  # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏≠‡∏¢‡∏≤‡∏Å‡∏î‡∏π‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "            }\n",
    "    return None\n",
    "\n",
    "latest = latest_eval_metric(trainer, key=\"eval_loss\")\n",
    "\n",
    "if latest is not None:\n",
    "    print(f\"Latest eval_loss: {latest['value']} (step={latest['step']}, epoch={latest['epoch']})\")\n",
    "else:\n",
    "    # fallback: ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏ó‡∏µ‡πà‡∏ú‡∏•‡∏£‡∏ß‡∏°‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n",
    "    print(\"Latest eval_loss: N/A\")\n",
    "    print(\"Final eval_loss (if present):\", trainer_stats.metrics.get(\"eval_loss\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9204ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Eval metrics (latest): {'eval_loss': 3.652217149734497, 'eval_runtime': 13.7634, 'eval_samples_per_second': 1.744, 'eval_steps_per_second': 1.744, 'epoch': 0.03, 'macro_f1': 0.0, 'rougeL': 0.6519686147517801, 'eval_macro_f1': 0.0, 'eval_rougeL': 0.6519686147517801}\n",
      "üîπ Eval loss: 3.652217149734497\n",
      "üîπ Macro F1: 0.0\n",
      "üîπ ROUGE-L: 0.6519686147517801\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = trainer.evaluate()\n",
    "\n",
    "print(\"üîπ Eval metrics (latest):\", eval_metrics)\n",
    "print(\"üîπ Eval loss:\", eval_metrics.get(\"eval_loss\"))\n",
    "print(\"üîπ Macro F1:\", eval_metrics.get(\"macro_f1\"))\n",
    "print(\"üîπ ROUGE-L:\", eval_metrics.get(\"rougeL\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
