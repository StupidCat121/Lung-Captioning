{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb3164a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.18\n",
      "Torch: 2.8.0+cu129\n",
      "Built with CUDA: 12.9\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch, platform\n",
    "\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Built with CUDA:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250b279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namth\\anaconda3\\envs\\lung_lora\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1008 23:53:02.122000 7512 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.9.11: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4050 Laptop GPU. Num GPUs = 1. Max memory: 5.997 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu129. CUDA: 8.9. CUDA Toolkit: 12.9. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastVisionModel\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-VL-3B-Instruct-bnb-4bit\",\n",
    "    load_in_4bit = True,\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52830999",
   "metadata": {},
   "source": [
    "‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ VLM ‡πÅ‡∏ö‡∏ö ‡∏™‡∏≠‡∏á‡∏á‡∏≤‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô: (1) ‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡πÇ‡∏£‡∏Ñ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û X-ray (classification) + (2) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏û (captioning) ‡∏ö‡∏ô‡∏ä‡∏∏‡∏î 6,000 ‡∏Ñ‡∏π‡πà‡∏†‡∏≤‡∏û‚Äì‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "\n",
    "‡∏≠‡∏≤‡∏Å‡∏≤‡∏£ ‚Äú‡∏ó‡∏≤‡∏¢‡πÇ‡∏£‡∏Ñ‡πÄ‡∏î‡∏¥‡∏°‡∏ã‡πâ‡∏≥ (‡πÄ‡∏ä‡πà‡∏ô normal) ‡∏à‡∏ô‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ï‡∏Å‡πÄ‡∏´‡∏•‡∏∑‡∏≠ ~0.17‚Äù ‡∏°‡∏±‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å catastrophic forgetting / class collapse ‡πÅ‡∏•‡∏∞ ‡∏≠‡∏¥‡∏°‡∏ö‡∏≤‡∏•‡∏≤‡∏ô‡∏ã‡πå‡∏Ç‡∏≠‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (‡∏™‡πà‡∏ß‡∏ô‡∏†‡∏≤‡∏©‡∏≤/‡πÅ‡∏Ñ‡∏õ‡∏ä‡∏±‡∏ô‡∏Å‡∏•‡∏ö‡∏á‡∏≤‡∏ô‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î)\n",
    "\n",
    "‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏£‡∏±‡∏á‡∏™‡∏µ = ‡πÉ‡∏´‡πâ ‚Äú‡∏™‡∏≤‡∏¢‡∏†‡∏≤‡∏û‚Äù ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏î‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤ ‚Äú‡∏™‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‚Äù ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏õ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏ß‡∏¢‡πÜ ‡πÅ‡∏ï‡πà ‡πÑ‡∏°‡πà‡∏à‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏™‡∏†‡∏≤‡∏û\n",
    "\n",
    "‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏´‡πâ ‚Äú‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏ö‡∏ö‡∏≠‡∏ô‡∏∏‡∏£‡∏±‡∏Å‡∏©‡πå‡∏ô‡∏¥‡∏¢‡∏°‚Äù: ‡∏ù‡∏∂‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ vision + cross-attention ‡∏Å‡πà‡∏≠‡∏ô, ‡∏Ñ‡∏∏‡∏° LoRA ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡∏≤‡∏á, ‡πÉ‡∏™‡πà dropout ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfit, ‡πÄ‡∏õ‡∏¥‡∏î rsLoRA ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Ç‡∏∂‡πâ‡∏ô ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å (6k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9df6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.15.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 1) PEFT / LoRA config (‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡πÇ‡∏à‡∏ó‡∏¢‡πå 2 ‡∏á‡∏≤‡∏ô: cls + cap)\n",
    "#    - ‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏±‡πâ‡∏á vision + attention ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏†‡∏≤‡∏û-‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "#    - ‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å \"‡∏Å‡∏±‡∏ô drift ‡∏†‡∏≤‡∏©‡∏≤\" ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î language MLP; ‡∏à‡∏∞‡∏Ñ‡πà‡∏≠‡∏¢ ‡πÜ ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ô‡∏£‡∏≠‡∏ö‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡πÑ‡∏î‡πâ\n",
    "#    - ‡πÉ‡∏ä‡πâ rsLoRA ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Å‡∏±‡∏ö rank ‡∏™‡∏π‡∏á\n",
    "# ==========================\n",
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = True,    # ‚úÖ ‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏™‡∏†‡∏≤‡∏û/feature ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á\n",
    "    finetune_language_layers   = False,   # ‚úÖ ‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å‡∏Å‡∏±‡∏ô drift ‡∏†‡∏≤‡∏©‡∏≤ (‡∏¢‡∏±‡∏á generate ‡πÑ‡∏î‡πâ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ head/weights ‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô infer)\n",
    "    finetune_attention_modules = True,    # ‚úÖ ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö cross-modal alignment (‡∏†‡∏≤‡∏û‚Üî‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)\n",
    "    finetune_mlp_modules       = False,   # ‚úÖ ‡∏•‡∏î‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏° ‡∏Å‡∏±‡∏ô overfit / catastrophic forgetting\n",
    "\n",
    "    r = 16,                # ‚úÖ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà 16; ‡∏ñ‡πâ‡∏≤ underfit ‡∏Ñ‡πà‡∏≠‡∏¢‡∏Ç‡∏¢‡∏±‡∏ö 32 ‡∏û‡∏£‡πâ‡∏≠‡∏° rsLoRA\n",
    "    lora_alpha = 16,       # ‚úÖ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö r ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ Unsloth\n",
    "    lora_dropout = 0.15,   # ‚úÖ ‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏±‡∏ô overfit/‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏î‡∏¥‡∏° (‡πÄ‡∏ä‡πà‡∏ô‡∏ï‡∏≠‡∏ö \"Normal\" ‡∏£‡∏±‡∏ß ‡πÜ)\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "\n",
    "    use_rslora = True,     # ‚úÖ ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Å‡∏±‡∏ö rank ‡∏™‡∏π‡∏á/‡∏á‡∏≤‡∏ô‡∏¢‡∏≤‡∏Å\n",
    "    loftq_config = None,   # ‚úÖ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏ó‡∏£‡∏ô 4-bit ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏õ‡∏¥‡∏î LoftQ ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û\n",
    "    # target_modules = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],  # ‚Üî ‡∏ñ‡πâ‡∏≤‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞ attention ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏Ñ‡πà‡∏≠‡∏¢‡∏õ‡∏•‡∏î‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af421c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "hf = load_from_disk(\"lung8_image_text\")\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á train/test (30%) ‡∏Å‡πà‡∏≠‡∏ô\n",
    "splits = hf.train_test_split(test_size=0.3, seed=42, shuffle=True)\n",
    "train_hf = splits[\"train\"]\n",
    "tmp_hf   = splits[\"test\"]\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á tmp ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô val/test ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡∏Ñ‡∏£‡∏∂‡πà‡∏á ‚Üí ‡πÑ‡∏î‡πâ 15/15\n",
    "vt = tmp_hf.train_test_split(test_size=0.5, seed=42, shuffle=True)\n",
    "val_hf  = vt[\"train\"]\n",
    "test_hf = vt[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3751e5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text', '__class__'],\n",
       "    num_rows: 4259\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "936a07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Describe the chest X-ray using precise clinical terms. Identify one main diagnostic category from: Chest_Changes, Degenerative_Infectious, Higher_Density, Inflammatory_Pneumonia, Lower_Density, Mediastinal_Changes, Normal, or Obstructive.\"\n",
    "\n",
    "def convert_to_conversation(sample):\n",
    "    cls_name = sample[\"__class__\"]\n",
    "    description = sample[\"text\"]\n",
    "\n",
    "    answer = f\"Class: {cls_name}\\nExplanation: {description}\"\n",
    "    \n",
    "    conversation = [\n",
    "        {\"role\": \"user\", \"content\" : [\n",
    "            {\"type\" : \"text\",  \"text\"  : instruction},\n",
    "            {\"type\" : \"image\", \"image\" : sample[\"image\"]} ]\n",
    "        },\n",
    "        {\"role\" : \"assistant\", \"content\" : [\n",
    "            {\"type\" : \"text\", \"text\" : answer} ]\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    return {\"messages\" : conversation}\n",
    "\n",
    "train_ds = [convert_to_conversation(sample) for sample in train_hf]\n",
    "val_ds = [convert_to_conversation(sample) for sample in val_hf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ea7b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Describe the chest X-ray using precise clinical terms. Identify one main diagnostic category from: Chest_Changes, Degenerative_Infectious, Higher_Density, Inflammatory_Pneumonia, Lower_Density, Mediastinal_Changes, Normal, or Obstructive.'},\n",
       "    {'type': 'image',\n",
       "     'image': <PIL.JpegImagePlugin.JpegImageFile image mode=L size=450x450>}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Class: Lower_Density\\nExplanation: Collapsed lung / visceral pleural line observed showing visceral pleural line with absent peripheral lung markings on the left side. A small amount of apical collapse is noted. The remaining lung fields are clear. No associated pleural effusion is present. Findings are compatible with Lower density (pneumothorax, pneumomediastinum, pneumoperitoneum).'}]}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b610a",
   "metadata": {},
   "source": [
    "‡∏Ñ‡πà‡∏≤ SFTTrainer ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡πâ‡∏≠‡∏á ‚Äú‡∏Å‡∏±‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡∏•‡πà‡∏°/‡∏ï‡∏≠‡∏ö‡∏ã‡πâ‡∏≥ normal‚Äù ‡πÅ‡∏•‡∏∞ ‚Äú‡∏Ñ‡∏∏‡∏°‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ captioning ‡∏Å‡∏•‡∏ö‡∏á‡∏≤‡∏ô‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‚Äù ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡∏ï‡∏ä‡πå‡πÄ‡∏≠‡∏ü‡πÄ‡∏ü‡∏Å‡∏ó‡∏µ‡∏ü‡πÉ‡∏´‡∏ç‡πà‡∏û‡∏≠, ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏û‡∏≠‡∏î‡∏µ, ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ñ‡∏µ‡πà, ‡πÄ‡∏ã‡∏ü‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡∏∞ (‡∏ñ‡πâ‡∏≤‡∏ó‡∏≥‡πÑ‡∏î‡πâ) ‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å loss ‡πÉ‡∏´‡πâ‡∏ù‡∏±‡πà‡∏á classification ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤\n",
    "\n",
    "‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö compute_metrics ‡πÑ‡∏°‡πà ‚Äú‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‚Äù ‡πÅ‡∏ï‡πà ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏≤‡∏™‡∏•‡πà‡∏°/‡πÄ‡∏î‡∏≤‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÄ‡∏ä‡πà‡∏ô normal ‡∏£‡∏±‡∏ß ‡πÜ) ‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏™‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (accuracy/F1 ‡∏ï‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™, BLEU/CIDEr ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Ñ‡∏õ‡∏ä‡∏±‡∏ô) ‡πÅ‡∏ó‡∏ô‡∏à‡∏∞‡∏î‡∏π loss ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2942a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import is_bf16_supported, FastVisionModel\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from transformers import EarlyStoppingCallback, TrainerCallback\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch, math, random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eae1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 2) ‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏á‡∏≤‡∏ô (label set) ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏•‡πá‡∏Å ‡πÜ\n",
    "# ==========================\n",
    "CLASS_LABELS = [\n",
    "    \"Chest_Changes\", \"Degenerative_Infectious\", \"Higher_Density\",\n",
    "    \"Inflammatory_Pneumonia\", \"Lower_Density\", \"Mediastinal_Changes\",\n",
    "    \"Normal\", \"Obstructive\",\n",
    "]\n",
    "LABEL_SET = set(CLASS_LABELS)\n",
    "LABEL_TO_ID = {c:i for i,c in enumerate(CLASS_LABELS)}\n",
    "\n",
    "def extract_pred_class(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ‡∏î‡∏∂‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•:\n",
    "    ‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á/‡πÄ‡∏Ñ‡∏™/‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏•‡∏±‡∏ö/‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
    "    \"\"\"\n",
    "    # ‡∏´‡∏≤ \"Class: <‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™>\"\n",
    "    m = re.search(r\"(?i)class\\s*:\\s*([A-Za-z0-9_\\- ]+)\", text)\n",
    "    if not m:\n",
    "        return None\n",
    "    raw = m.group(1).strip()\n",
    "    # ‡∏ó‡∏≥ normalization ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
    "    cand = raw.replace(\" \", \"_\")\n",
    "    # ‡πÄ‡∏ä‡πá‡∏Ñ map ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å (‡πÅ‡∏ö‡∏ö‡∏´‡∏¢‡∏ß‡∏ô‡πÜ)\n",
    "    # ‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏ï‡∏±‡∏ß‡∏Å‡πà‡∏≠‡∏ô\n",
    "    if cand in LABEL_TO_ID: \n",
    "        return cand\n",
    "    # ‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ö‡∏ö lower-case\n",
    "    for c in CLASS_LABELS:\n",
    "        if cand.lower() == c.lower():\n",
    "            return c\n",
    "    # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô None ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏à‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d59ebddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = \"\"\"\n",
    "Class: mEdiAsTinal cHanges\n",
    "Explanation: The chest X-ray shows increased transparency adjacent to both right and left cardiophrenic angles with variable clarity indicating partial atelectasis or pneumonia. This imaging feature suggests inflammatory change that is consistent with an underlying infectious etiology in this setting. The clinical scenario strongly supports infection leading to lung parenchymal changes. There are no visible effusions, mass lesions, or linear changes typical for entities like neoplasms or autoimmune conditions. The features are compatible with Degenerative_Infectious based on clinical and radiographic correlation, particularly considering the known clinical presentations associated with specific conditions in similar\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b1528e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mediastinal_Changes'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_pred_class(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fda2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_l_f1(pred: str, ref: str) -> float:\n",
    "    \"\"\"\n",
    "    ROUGE-L F1 ‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ (‡πÑ‡∏°‡πà‡∏û‡∏∂‡πà‡∏á external lib) ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [0,1]\n",
    "    ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô proxy ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û captioning ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ CIDEr\n",
    "    \"\"\"\n",
    "    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô token ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ö‡∏ö‡∏´‡∏¢‡∏≤‡∏ö ‡πÜ\n",
    "    def tok(s): \n",
    "        return [w for w in s.strip().split() if w]\n",
    "    x, y = tok(pred.lower()), tok(ref.lower())\n",
    "    if not x or not y:\n",
    "        return 0.0\n",
    "    # LCS length (dynamic programming)\n",
    "    m, n = len(x), len(y)\n",
    "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if x[i] == y[j]:\n",
    "                dp[i+1][j+1] = dp[i][j] + 1\n",
    "            else:\n",
    "                dp[i+1][j+1] = max(dp[i][j+1], dp[i+1][j])\n",
    "    lcs = dp[m][n]\n",
    "    prec = lcs / max(1, m)\n",
    "    rec  = lcs / max(1, n)\n",
    "    if prec + rec == 0:\n",
    "        return 0.0\n",
    "    return 2 * prec * rec / (prec + rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a53fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_t = \"\"\"\n",
    "Class: Mediastinal_Changes\n",
    "Explanation: Findings are compatible with Arteriovenous malformations (pulmonary AVM may project as nodular opacity), characterized by well-circumscribed nodular opacity with suspected vascular connections may reflect pulmonary AVM (confirm on CT/angio). The nodular opacity warrants careful evaluation. Further imaging, such as a CT angiogram, is crucial for confirmation and characterization of feeding/draining vessels.\n",
    "\"\"\"\n",
    "\n",
    "ref_f = \"\"\"\n",
    "Class: Degenerative_Infectious\n",
    "Explanation: Reticulonodular pattern / interstitial fibrosis with coarse reticular opacities with volume loss, basilar and peripheral predominance (fibrotic pattern on CXR). Findings are compatible with Pulmonary fibrosis (e.g., IPF pattern on CXR). The reticular opacities are most evident in the lower lobes and periphery. There is associated volume loss and architectural distortion. These findings are highly suggestive of a fibrotic lung disease.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fce834c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09333333333333334"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_l_f1(test_pred, ref_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48fda8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_l_f1(test_pred, ref_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81b6abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1_from_predictions(y_true: List[int], y_pred: List[int]) -> float:\n",
    "    \"\"\"\n",
    "    macro-F1 ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏∂‡πà‡∏á sklearn (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° self-contained)\n",
    "    \"\"\"\n",
    "    num_classes = len(CLASS_LABELS)\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á confusion ‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡∏ö TP/FP/FN ‡∏ï‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™\n",
    "    tp = [0]*num_classes\n",
    "    fp = [0]*num_classes\n",
    "    fn = [0]*num_classes\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yp == yt:\n",
    "            tp[yt] += 1\n",
    "        else:\n",
    "            fp[yp] += 1\n",
    "            fn[yt] += 1\n",
    "    f1s = []\n",
    "    for c in range(num_classes):\n",
    "        p = tp[c] / max(1, (tp[c] + fp[c]))\n",
    "        r = tp[c] / max(1, (tp[c] + fn[c]))\n",
    "        if p + r == 0:\n",
    "            f1s.append(0.0)\n",
    "        else:\n",
    "            f1s.append(2*p*r/(p+r))\n",
    "    return float(np.mean(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==========================\n",
    "# # 3) Callback: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô cls + cap ‡πÅ‡∏•‡πâ‡∏ß \"‡∏•‡πá‡∏≠‡∏Å\" metric\n",
    "# #    - ‡πÉ‡∏ä‡πâ subset ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£\n",
    "# #    - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° prompt ‡∏ï‡∏≤‡∏° chat template ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡∏π‡πà\n",
    "# # ==========================\n",
    "# class CaptionEvalCallback(TrainerCallback):\n",
    "#     def __init__(self, eval_dataset, tokenizer, sample_size=256, max_new_tokens=96, seed=42):\n",
    "#         self.eval_dataset = eval_dataset\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.sample_size = sample_size\n",
    "#         self.max_new_tokens = max_new_tokens\n",
    "#         self.rng = random.Random(seed)\n",
    "\n",
    "#     def build_messages(self, image_obj) -> Dict[str, Any]:\n",
    "#         \"\"\"\n",
    "#         ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö messages ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:\n",
    "#         {'messages': [\n",
    "#             {'role': 'user', 'content': [{'type':'text',...}, {'type':'image',...}]}\n",
    "#         ]}\n",
    "#         ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡∏±‡πâ‡∏á prompt ‡πÇ‡∏Ñ‡∏£‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö data ‡∏ó‡∏µ‡πà‡∏™‡∏±‡πà‡∏á‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö convert_to_conversation ‡πÑ‡∏ß‡πâ\n",
    "#         \"\"\"\n",
    "#         return {\n",
    "#             \"messages\": [\n",
    "#                 {\n",
    "#                     \"role\": \"user\",\n",
    "#                     \"content\": [\n",
    "#                         {\"type\": \"text\",\n",
    "#                             \"text\": \"Describe the chest X-ray using precise clinical terms. \"\n",
    "#                                     \"Identify one main diagnostic category from: Chest_Changes, Degenerative_Infectious, \"\n",
    "#                                     \"Higher_Density, Inflammatory_Pneumonia, Lower_Density, Mediastinal_Changes, Normal, or Obstructive.\"},\n",
    "#                         {\"type\": \"image\", \"image\": image_obj},\n",
    "#                     ],\n",
    "#                 }\n",
    "#             ]\n",
    "#         }\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def on_evaluate(self, args, state, control, model=None, **kwargs):\n",
    "#         model.eval()\n",
    "\n",
    "#         # ----- ‡∏™‡∏∏‡πà‡∏° subset ‡∏à‡∏≤‡∏Å val_ds ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤ evaluate -----\n",
    "#         n = len(self.eval_dataset)\n",
    "#         idxs = list(range(n))\n",
    "#         self.rng.shuffle(idxs)\n",
    "#         idxs = idxs[:min(self.sample_size, n)]\n",
    "\n",
    "#         pred_classes, true_classes = [], []\n",
    "#         rouge_ls = []\n",
    "\n",
    "#         for i in idxs:\n",
    "#             row = self.eval_dataset[i]\n",
    "#             image_obj = row[\"image\"]      # PIL image\n",
    "#             true_cls  = row[\"__class__\"]  # ground-truth label string\n",
    "\n",
    "#             # ----- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏ï‡∏≤‡∏° template ‡∏Ç‡∏≠‡∏á‡∏£‡∏∏‡πà‡∏ô -----\n",
    "#             messages = self.build_messages(image_obj)\n",
    "#             # Unsloth: ‡πÉ‡∏ä‡πâ tokenizer.apply_chat_template ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà model ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à\n",
    "#             inputs = self.tokenizer.apply_chat_template(\n",
    "#                 messages[\"messages\"],\n",
    "#                 add_generation_prompt=True,\n",
    "#                 tokenize=True,\n",
    "#                 return_tensors=\"pt\"\n",
    "#             ).to(model.device)\n",
    "\n",
    "#             # ----- ‡πÅ‡∏ô‡∏ö‡∏†‡∏≤‡∏û (FastVisionModel ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ú‡πà‡∏≤‡∏ô processor ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•) -----\n",
    "#             # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Unsoth FastVisionModel ‡∏õ‡∏Å‡∏ï‡∏¥ data_collator ‡∏à‡∏∞‡∏î‡∏π‡πÅ‡∏•‡∏†‡∏≤‡∏û\n",
    "#             # ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏ò‡∏¥‡∏ï‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ids (‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ processor)\n",
    "#             # ‡∏´‡∏≤‡∏Å‡∏£‡∏∏‡πà‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ processor ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô kwargs = processor(...)\n",
    "\n",
    "#             # ----- Generate -----\n",
    "#             out = model.generate(\n",
    "#                 input_ids=inputs,\n",
    "#                 max_new_tokens=self.max_new_tokens,\n",
    "#                 do_sample=False\n",
    "#             )\n",
    "#             text = self.tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "#             # ----- ‡πÅ‡∏¢‡∏Å \"‡∏Ñ‡∏•‡∏≤‡∏™\" ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ROUGE-L caption -----\n",
    "#             pred_cls_str = extract_pred_class(text) or \"\"   # string ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå\n",
    "#             if pred_cls_str in LABEL_SET:\n",
    "#                 pred_classes.append(LABEL_TO_ID[pred_cls_str])\n",
    "#             else:\n",
    "#                 # ‡∏ñ‡πâ‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡∏•‡∏á -1 ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏Å‡∏£‡∏≠‡∏á‡∏≠‡∏≠‡∏Å\n",
    "#                 pred_classes.append(-1)\n",
    "\n",
    "#             true_classes.append(LABEL_TO_ID.get(true_cls, -1))\n",
    "\n",
    "#             # ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö caption ‡∏Å‡∏±‡∏ö reference\n",
    "#             # - ‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì reference caption ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô field \"text\" (‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á convert_to_conversation)\n",
    "#             ref_caption = row.get(\"text\", \"\") or \"\"\n",
    "#             rouge_ls.append(rouge_l_f1(text, ref_caption))\n",
    "\n",
    "#         # ----- ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ -1 -----\n",
    "#         y_true_clean, y_pred_clean = [], []\n",
    "#         for yt, yp in zip(true_classes, pred_classes):\n",
    "#             if yt >= 0 and yp >= 0:\n",
    "#                 y_true_clean.append(yt)\n",
    "#                 y_pred_clean.append(yp)\n",
    "\n",
    "#         macro_f1 = macro_f1_from_predictions(y_true_clean, y_pred_clean) if y_true_clean else 0.0\n",
    "#         rougeL   = float(np.mean(rouge_ls)) if rouge_ls else 0.0\n",
    "\n",
    "#         # ----- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤ metric ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á Trainer -----\n",
    "#         # ‡πÉ‡∏™‡πà‡πÉ‡∏ô state.log_history ‡∏ú‡πà‡∏≤‡∏ô trainer.log ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ control ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡πà‡∏≤\n",
    "#         # ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏™‡πà‡∏•‡∏á‡πÉ‡∏ô kwargs['metrics'] ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ (HF >= 4.41 ‡∏°‡∏±‡∏Å‡∏™‡πà‡∏á metrics ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤)\n",
    "#         metrics = kwargs.get(\"metrics\", {})\n",
    "#         metrics[\"macro_f1\"] = macro_f1            # ‚úÖ metric ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å best\n",
    "#         metrics[\"rougeL\"]   = rougeL              # ‚úÖ proxy ‡∏Ç‡∏≠‡∏á caption ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û (0‚Äì1)\n",
    "#         # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ CIDEr ‡∏à‡∏£‡∏¥‡∏á ‡πÉ‡∏´‡πâ‡πÅ‡∏ó‡∏ô‡∏î‡πâ‡∏ß‡∏¢ metrics[\"cider\"] = compute_cider(...)\n",
    "#         kwargs[\"metrics\"] = metrics\n",
    "\n",
    "#         # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô metrics ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å logger ‡∏Ç‡∏≠‡∏á Trainer ‡πÄ‡∏Å‡πá‡∏ö ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö EarlyStopping/metric_for_best_model\n",
    "#         return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad602ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 3) Callback: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô cls + cap ‡πÅ‡∏•‡πâ‡∏ß \"‡∏•‡πá‡∏≠‡∏Å\" metric (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô KeyError)\n",
    "# ==========================\n",
    "class CaptionEvalCallback(TrainerCallback):\n",
    "    def __init__(self, eval_dataset, tokenizer, sample_size=256, max_new_tokens=96, seed=42):\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sample_size = sample_size\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "        self.rng = random.Random(seed)\n",
    "\n",
    "    # --- ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ messages ‡πÉ‡∏ô row ---\n",
    "    def build_messages(self, image_obj) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        ‡∏Å‡∏£‡∏ì‡∏µ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤ (‡∏°‡∏µ 'image' ‡πÅ‡∏•‡∏∞ 'text') ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ 'messages'\n",
    "        ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° user ‡∏ï‡∏≤‡∏° prompt ‡πÄ‡∏î‡∏¥‡∏° + ‡πÅ‡∏ô‡∏ö‡∏†‡∏≤‡∏û\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\",\n",
    "                         \"text\": (\n",
    "                            \"Describe the chest X-ray using precise clinical terms. \"\n",
    "                            \"Identify one main diagnostic category from: \"\n",
    "                            \"Chest_Changes, Degenerative_Infectious, Higher_Density, \"\n",
    "                            \"Inflammatory_Pneumonia, Lower_Density, Mediastinal_Changes, \"\n",
    "                            \"Normal, or Obstructive.\"\n",
    "                         )},\n",
    "                        {\"type\": \"image\", \"image\": image_obj},\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def _extract_from_row(self, row: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å‡∏Å‡∏£‡∏ì‡∏µ:\n",
    "        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ 'messages': ‡πÉ‡∏ä‡πâ messages ‡πÄ‡∏î‡∏¥‡∏° (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢, ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á chat template)\n",
    "            * ‡∏£‡∏π‡∏õ: ‡∏Ñ‡πâ‡∏ô‡πÉ‡∏ô user.content[type=='image']\n",
    "            * ref_caption: ‡πÉ‡∏ä‡πâ assistant.content[type=='text'] ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'text'\n",
    "        - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ 'messages': ‡πÉ‡∏ä‡πâ row['image'] + row['text'] ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏£‡πâ‡∏≤‡∏á messages ‡πÉ‡∏´‡∏°‡πà\n",
    "\n",
    "        ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: messages(dict), ref_caption(str), true_cls(str)\n",
    "        \"\"\"\n",
    "        messages = None\n",
    "        ref_caption = row.get(\"text\", \"\") or \"\"       # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ 'text' ‡∏à‡∏∞‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏à‡∏≤‡∏Å assistant ‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á\n",
    "        true_cls = row.get(\"__class__\", \"\") or \"\"     # label ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™\n",
    "\n",
    "        if \"messages\" in row and isinstance(row[\"messages\"], list):\n",
    "            # ‡πÉ‡∏ä‡πâ messages ‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á mismatch ‡∏Å‡∏±‡∏ö processor/data_collator\n",
    "            messages = {\"messages\": row[\"messages\"]}\n",
    "\n",
    "            # ‡∏´‡∏≤ image ‡∏à‡∏≤‡∏Å user turn ‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ type=='image'\n",
    "            image_found = False\n",
    "            for turn in row[\"messages\"]:\n",
    "                if turn.get(\"role\") == \"user\":\n",
    "                    for c in (turn.get(\"content\") or []):\n",
    "                        if isinstance(c, dict) and c.get(\"type\") == \"image\" and c.get(\"image\") is not None:\n",
    "                            image_found = True\n",
    "                            break\n",
    "                if image_found:\n",
    "                    break\n",
    "\n",
    "            # ‡∏´‡∏≤ ref caption ‡∏à‡∏≤‡∏Å assistant ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ 'text'\n",
    "            if not ref_caption:\n",
    "                for turn in row[\"messages\"]:\n",
    "                    if turn.get(\"role\") == \"assistant\":\n",
    "                        for c in (turn.get(\"content\") or []):\n",
    "                            if isinstance(c, dict) and c.get(\"type\") == \"text\" and c.get(\"text\"):\n",
    "                                ref_caption = c[\"text\"]\n",
    "                                break\n",
    "                        if ref_caption:\n",
    "                            break\n",
    "\n",
    "            # ‡∏ñ‡πâ‡∏≤ messages ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏û‡πÄ‡∏•‡∏¢ (rare) ‚Üí ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° fallback ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏µ‡∏¢‡πå 'image'\n",
    "            if not image_found and row.get(\"image\", None) is not None:\n",
    "                messages = self.build_messages(row[\"image\"])\n",
    "\n",
    "        else:\n",
    "            # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ 'image' ‡∏à‡∏∂‡∏á‡∏à‡∏∞ build ‡πÑ‡∏î‡πâ\n",
    "            img = row.get(\"image\", None)\n",
    "            if img is None:\n",
    "                # ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‚Üí ‡πÇ‡∏¢‡∏ô error ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏ó‡∏ô KeyError\n",
    "                raise ValueError(\n",
    "                    \"No image found in row. Expected either 'messages' with an image content \"\n",
    "                    \"or an 'image' column.\"\n",
    "                )\n",
    "            messages = self.build_messages(img)\n",
    "\n",
    "        return messages, ref_caption, true_cls\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def on_evaluate(self, args, state, control, model=None, **kwargs):\n",
    "        model.eval()\n",
    "\n",
    "        # ----- ‡∏™‡∏∏‡πà‡∏° subset ‡∏à‡∏≤‡∏Å val_ds ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤ evaluate -----\n",
    "        n = len(self.eval_dataset)\n",
    "        idxs = list(range(n))\n",
    "        self.rng.shuffle(idxs)\n",
    "        idxs = idxs[:min(self.sample_size, n)]\n",
    "\n",
    "        pred_classes, true_classes = [], []\n",
    "        rouge_ls = []\n",
    "\n",
    "        for i in idxs:\n",
    "            row = self.eval_dataset[i]\n",
    "\n",
    "            # ‚úÖ ‡∏î‡∏∂‡∏á messages/ref/label ‡πÅ‡∏ö‡∏ö‡∏Å‡∏±‡∏ô‡∏û‡∏±‡∏á ‡πÑ‡∏°‡πà‡∏ú‡∏π‡∏Å‡∏ï‡∏¥‡∏î‡∏Ñ‡∏µ‡∏¢‡πå 'image'\n",
    "            messages, ref_caption, true_cls = self._extract_from_row(row)\n",
    "\n",
    "            # ----- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏ï‡∏≤‡∏° template ‡∏Ç‡∏≠‡∏á‡∏£‡∏∏‡πà‡∏ô (‡πÉ‡∏ä‡πâ messages ‡∏ó‡∏µ‡πà‡∏™‡∏Å‡∏±‡∏î‡πÑ‡∏î‡πâ) -----\n",
    "            inputs = self.tokenizer.apply_chat_template(\n",
    "                messages[\"messages\"],\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "\n",
    "            # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: Unsloth FastVisionModel ‡∏à‡∏∞ map ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å messages ‡∏ú‡πà‡∏≤‡∏ô data_collator/processor ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô\n",
    "            # ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏£‡∏∏‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ kwargs ‡πÄ‡∏û‡∏¥‡πà‡∏° (‡πÄ‡∏ä‡πà‡∏ô pixel_values) ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏±‡∏ö data_collator ‡πÉ‡∏´‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô\n",
    "\n",
    "            # ----- Generate -----\n",
    "            out = model.generate(\n",
    "                input_ids=inputs,\n",
    "                max_new_tokens=self.max_new_tokens,\n",
    "                do_sample=False\n",
    "            )\n",
    "            text = self.tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "            # ----- ‡πÅ‡∏¢‡∏Å \"‡∏Ñ‡∏•‡∏≤‡∏™\" ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ROUGE-L caption -----\n",
    "            pred_cls_str = extract_pred_class(text) or \"\"   # string ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå\n",
    "            if pred_cls_str in LABEL_SET:\n",
    "                pred_classes.append(LABEL_TO_ID[pred_cls_str])\n",
    "            else:\n",
    "                pred_classes.append(-1)  # ‡∏ñ‡πâ‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å‡πÉ‡∏´‡πâ mark -1 ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á\n",
    "\n",
    "            true_classes.append(LABEL_TO_ID.get(true_cls, -1))\n",
    "\n",
    "            # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ ref_caption ‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà \"\" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ rouge_l_f1 ‡∏Ñ‡∏∑‡∏ô 0 ‡πÅ‡∏ó‡∏ô‡∏û‡∏±‡∏á\n",
    "            rouge_ls.append(rouge_l_f1(text, ref_caption or \"\"))\n",
    "\n",
    "        # ----- ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ -1 -----\n",
    "        y_true_clean, y_pred_clean = [], []\n",
    "        for yt, yp in zip(true_classes, pred_classes):\n",
    "            if yt >= 0 and yp >= 0:\n",
    "                y_true_clean.append(yt)\n",
    "                y_pred_clean.append(yp)\n",
    "\n",
    "        macro_f1 = macro_f1_from_predictions(y_true_clean, y_pred_clean) if y_true_clean else 0.0\n",
    "        rougeL   = float(np.mean(rouge_ls)) if rouge_ls else 0.0\n",
    "\n",
    "        # ----- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤ metric ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á Trainer -----\n",
    "        metrics = kwargs.get(\"metrics\", {})\n",
    "        metrics[\"macro_f1\"] = macro_f1            # ‚úÖ metric ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å best\n",
    "        metrics[\"rougeL\"]   = rougeL              # ‚úÖ proxy ‡∏Ç‡∏≠‡∏á caption ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û (0‚Äì1)\n",
    "        kwargs[\"metrics\"] = metrics\n",
    "\n",
    "        return control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adad647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==========================\n",
    "# # 4) Callback: Gate ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å captioning (‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥) + Early stopping ‡πÄ‡∏™‡∏£‡∏¥‡∏°\n",
    "# #    - ‡∏ñ‡πâ‡∏≤ rougeL ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ min_value ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô 'patience' ‡∏£‡∏≠‡∏ö ‚Üí ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏ó‡∏£‡∏ô\n",
    "# #    - ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ save checkpoint ‡πÉ‡∏ô‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô\n",
    "# # ==========================\n",
    "# class SecondaryMetricGate(TrainerCallback):\n",
    "#     def __init__(self, metric_key=\"rougeL\", min_value=0.35, patience=2):\n",
    "#         self.metric_key = metric_key\n",
    "#         self.min_value = min_value\n",
    "#         self.patience = patience\n",
    "#         self.bad_epochs = 0\n",
    "\n",
    "#     def on_evaluate(self, args, state, control, **kwargs):\n",
    "#         metrics = kwargs.get(\"metrics\", {}) or {}\n",
    "#         val = metrics.get(self.metric_key, None)\n",
    "#         if val is None:\n",
    "#             # ‡πÑ‡∏°‡πà‡∏°‡∏µ metric caption ‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ ‚Üí ‡πÑ‡∏°‡πà gate\n",
    "#             return control\n",
    "\n",
    "#         if val < self.min_value:\n",
    "#             # 1) ‡πÑ‡∏°‡πà save checkpoint ‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ (‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡∏ó‡∏µ‡πà caption ‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å)\n",
    "#             control.should_save = False\n",
    "#             # 2) ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠ early stop\n",
    "#             self.bad_epochs += 1\n",
    "#             if self.bad_epochs >= self.patience:\n",
    "#                 control.should_training_stop = True\n",
    "#         else:\n",
    "#             self.bad_epochs = 0\n",
    "\n",
    "#         return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94fe1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 4) Callback: Gate ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å captioning (‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥) + Early stopping ‡πÄ‡∏™‡∏£‡∏¥‡∏°\n",
    "#    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏µ‡∏¢‡πå \"rougeL\" ‡πÅ‡∏•‡∏∞ \"eval_rougeL\" ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "# ==========================\n",
    "class SecondaryMetricGate(TrainerCallback):\n",
    "    def __init__(self, metric_key=\"rougeL\", min_value=0.35, patience=2):\n",
    "        self.metric_key = metric_key          # ‡πÄ‡∏ä‡πà‡∏ô \"rougeL\" ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡∏™‡πà‡∏á \"eval_rougeL\" ‡∏°‡∏≤‡∏Å‡πá‡πÑ‡∏î‡πâ\n",
    "        self.min_value = float(min_value)\n",
    "        self.patience = int(patience)\n",
    "        self.bad_epochs = 0\n",
    "\n",
    "    def _get_metric(self, metrics: dict):\n",
    "        \"\"\"‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏µ‡∏¢‡πå‡∏õ‡∏Å‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ prefix 'eval_'\"\"\"\n",
    "        if self.metric_key in metrics:\n",
    "            return metrics[self.metric_key]\n",
    "        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏•‡∏≠‡∏á‡πÄ‡∏ï‡∏¥‡∏°/‡∏ï‡∏±‡∏î prefix 'eval_'\n",
    "        if self.metric_key.startswith(\"eval_\"):\n",
    "            alt = self.metric_key.replace(\"eval_\", \"\", 1)\n",
    "            return metrics.get(alt, None)\n",
    "        else:\n",
    "            alt = f\"eval_{self.metric_key}\"\n",
    "            return metrics.get(alt, None)\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        metrics = kwargs.get(\"metrics\", {}) or {}\n",
    "        val = self._get_metric(metrics)\n",
    "        if val is None:\n",
    "            # ‡πÑ‡∏°‡πà‡∏°‡∏µ metric ‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ ‚Üí ‡πÑ‡∏°‡πà gate\n",
    "            return control\n",
    "\n",
    "        if val < self.min_value:\n",
    "            # 1) ‡πÑ‡∏°‡πà save checkpoint ‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ (‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡∏ó‡∏µ‡πà caption ‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å)\n",
    "            control.should_save = False\n",
    "            # 2) ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à early stop\n",
    "            self.bad_epochs += 1\n",
    "            if self.bad_epochs >= self.patience:\n",
    "                control.should_training_stop = True\n",
    "        else:\n",
    "            self.bad_epochs = 0\n",
    "\n",
    "        return control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "800c8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 5) ‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ö‡∏ô GPU (TF32) + ‡πÄ‡∏õ‡∏¥‡∏î train\n",
    "# ==========================\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "FastVisionModel.for_training(model)  # ‚úÖ enable training\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10109336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==========================\n",
    "# # 6) ‡∏™‡∏£‡πâ‡∏≤‡∏á Trainer + ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å \"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\" ‡∏î‡πâ‡∏ß‡∏¢ macro_f1\n",
    "# #    - eval/save ‡πÅ‡∏ö‡∏ö steps ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ callback ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ñ‡∏µ‡πà‡∏û‡∏≠\n",
    "# #    - remove_unused_columns=False ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö VLM (‡∏£‡∏±‡∏Å‡∏©‡∏≤ fields image/messages)\n",
    "# # ==========================\n",
    "# trainer = SFTTrainer(\n",
    "#     model = model,\n",
    "#     tokenizer = tokenizer,\n",
    "#     data_collator = UnslothVisionDataCollator(model, tokenizer),\n",
    "#     train_dataset = train_ds,\n",
    "#     eval_dataset = val_ds,\n",
    "#     args = SFTConfig(\n",
    "#         # ===== core =====\n",
    "#         output_dir=\"./outs\",\n",
    "#         per_device_train_batch_size=2,\n",
    "#         gradient_accumulation_steps=16,\n",
    "#         learning_rate=1e-4,\n",
    "#         num_train_epochs=2,\n",
    "#         warmup_ratio=0.05,\n",
    "#         weight_decay=0.01,\n",
    "#         lr_scheduler_type=\"linear\",\n",
    "\n",
    "#         # ===== precision =====\n",
    "#         bf16 = is_bf16_supported(),   # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏°‡∏Æ‡∏≤‡∏£‡πå‡∏î‡πÅ‡∏ß‡∏£‡πå (Ampere+)\n",
    "#         tf32 = True,\n",
    "\n",
    "#         # ===== eval/save =====\n",
    "#         eval_strategy=\"steps\",\n",
    "#         eval_steps=300,\n",
    "#         save_strategy=\"steps\",\n",
    "#         save_steps=300,\n",
    "#         load_best_model_at_end=True,\n",
    "\n",
    "#         # ‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ï‡∏≤‡∏° \"macro_f1\" (‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å: classification)\n",
    "#         metric_for_best_model=\"macro_f1\",\n",
    "#         greater_is_better=True,\n",
    "\n",
    "#         logging_steps=10,\n",
    "#         save_total_limit=3,           # ‚úÖ ‡∏Å‡∏±‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡πÄ‡∏¢‡∏≠‡∏∞\n",
    "\n",
    "#         # ===== VLM safety =====\n",
    "#         remove_unused_columns=False,  # ‚úÖ ‡∏≠‡∏¢‡πà‡∏≤‡∏ï‡∏±‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå messages/image\n",
    "#         dataloader_num_workers=0,     # ‚úÖ ‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤ pickle/vision worker\n",
    "#         dataset_num_proc=1,           # ‚úÖ ‡∏Å‡∏±‡∏ô map ‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏õ‡∏£‡πÄ‡∏ã‡∏™ (‡∏™‡πÄ‡∏ñ‡∏µ‡∏¢‡∏£)\n",
    "#         per_device_eval_batch_size=2, # ‚úÖ ‡∏•‡∏î VRAM ‡∏Ç‡∏ì‡∏∞ eval+generate\n",
    "#     ),\n",
    "#     # ‡πÄ‡∏£‡∏≤ \"‡πÑ‡∏°‡πà\" ‡πÉ‡∏ä‡πâ compute_metrics ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö SFTTrainer ‡∏ï‡∏£‡∏á ‡πÜ\n",
    "#     # ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ VLM+generate ‡∏°‡∏±‡∏Å‡∏ä‡∏ô‡∏Å‡∏±‡∏ö _pad_across_processes; ‡∏à‡∏∂‡∏á‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ callback\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84ac35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==========================\n",
    "# # 7) ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Callback:\n",
    "# #    - EarlyStopping: ‡∏≠‡∏¥‡∏á metric_for_best_model (macro_f1)\n",
    "# #    - CaptionEvalCallback: ‡πÄ‡∏ï‡∏¥‡∏° macro_f1 + rougeL ‡∏•‡∏á metrics ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà eval\n",
    "# #    - SecondaryMetricGate: ‡∏Å‡∏±‡πâ‡∏ô checkpoint/‡∏´‡∏¢‡∏∏‡∏î ‡∏´‡∏≤‡∏Å caption ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå\n",
    "# # ==========================\n",
    "# trainer.add_callback(EarlyStoppingCallback(\n",
    "#     early_stopping_patience=5,         # ‡∏ñ‡πâ‡∏≤ macro_f1 ‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô 5 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡∏¥‡∏î ‚Üí ‡∏´‡∏¢‡∏∏‡∏î\n",
    "#     early_stopping_threshold=1e-4\n",
    "# ))\n",
    "# trainer.add_callback(CaptionEvalCallback(\n",
    "#     eval_dataset=val_ds,\n",
    "#     tokenizer=tokenizer,\n",
    "#     sample_size=64,                   # ‚úÖ subset ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ)\n",
    "#     max_new_tokens=96\n",
    "# ))\n",
    "# trainer.add_callback(SecondaryMetricGate(\n",
    "#     metric_key=\"rougeL\",               # ‚úÖ ‡πÉ‡∏ä‡πâ ROUGE-L ‡πÄ‡∏õ‡πá‡∏ô proxy ‡∏Ç‡∏≠‡∏á caption ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û\n",
    "#     min_value=0.35,                    # ‚úÖ ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ (‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ê‡∏≤‡∏ô)\n",
    "#     patience=2\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dfdd04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Model does not have a default image size - using 512\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = UnslothVisionDataCollator(model, tokenizer),\n",
    "    train_dataset = train_ds,\n",
    "    eval_dataset = val_ds,\n",
    "    args = SFTConfig(\n",
    "        output_dir=\"./outs_fast\",\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=1e-4,\n",
    "        num_train_epochs=1,\n",
    "        max_steps=120,\n",
    "        warmup_ratio=0.0,\n",
    "        weight_decay=0.0,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        bf16 = is_bf16_supported(),\n",
    "        tf32 = True,\n",
    "\n",
    "        # ---- eval/save ----\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=40,\n",
    "        save_strategy=\"no\",          # ‡πÑ‡∏°‡πà‡πÄ‡∏ã‡∏ü ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î I/O\n",
    "        load_best_model_at_end=False,# ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å best\n",
    "\n",
    "        # ‚õî ‡∏•‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏ó‡∏¥‡πâ‡∏á‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏ó‡∏™‡∏ï‡πå:\n",
    "        # metric_for_best_model=\"macro_f1\",\n",
    "        # greater_is_better=True,\n",
    "\n",
    "        logging_steps=5,\n",
    "        save_total_limit=1,\n",
    "\n",
    "        remove_unused_columns=False,\n",
    "        dataloader_num_workers=0,\n",
    "        dataset_num_proc=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee0e44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏£‡πá‡∏ß: ‡πÉ‡∏ä‡πâ subset ‡πÄ‡∏•‡πá‡∏Å + generate ‡∏™‡∏±‡πâ‡∏ô\n",
    "trainer.add_callback(CaptionEvalCallback(\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    sample_size=32,        # ‡∏à‡∏≤‡∏Å 256 ‚Üí 32 ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å\n",
    "    max_new_tokens=40      # ‡∏à‡∏≤‡∏Å 96 ‚Üí 40 ‡∏û‡∏≠‡∏à‡∏±‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÑ‡∏î‡πâ\n",
    "))\n",
    "# ‡πÄ‡∏Å‡∏ó‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û caption ‡πÉ‡∏´‡πâ‡πÄ‡∏ö‡∏≤‡∏•‡∏á‡∏´‡∏ô‡πà‡∏≠‡∏¢ (‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ß‡∏•‡∏≤)\n",
    "trainer.add_callback(SecondaryMetricGate(\n",
    "    metric_key=\"rougeL\",\n",
    "    min_value=0.30,        # ‡∏ú‡πà‡∏≠‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏ó‡∏™‡∏ï‡πå\n",
    "    patience=1             # ‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≥ 1 ‡∏£‡∏≠‡∏ö‡∏ï‡∏¥‡∏î‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4badd9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4050 Laptop GPU. Max memory = 5.997 GB.\n",
      "6.238 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import unsloth_train\n",
    "\n",
    "trainer_stats = unsloth_train(trainer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
